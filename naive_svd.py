# -*- coding: utf-8 -*-
"""NAIVE_SVD

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mNjKMQytE3968ym7wZhqB_FgAjWBSVxP
"""

import logging
import pandas as pd
import numpy as np
from numpy import random
import gensim
import nltk
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
from nltk.corpus import stopwords
import re
from bs4 import BeautifulSoup
url="https://storage.googleapis.com/tensorflow-workshop-examples/stack-overflow-data.csv"
df = pd.read_csv(url)
df = df[pd.notnull(df['tags'])]

print(df.head(10))
print(df['post'].apply(lambda x: len(x.split(' '))).sum())

def print_plot(index):
    example = df[df.index == index][['post', 'tags']].values[0]
    if len(example) > 0:
        print(example[0])
        print('Tag:', example[1])

print_plot(10)

nltk.download('stopwords')

REPLACE_BY_SPACE_RE = re.compile('[/(){}\[\]\|@,;]')
BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')
STOPWORDS = set(stopwords.words('english'))

def clean_text(text):
    """
        text: a string
        
        return: modified initial string
    """
    text = BeautifulSoup(text, "lxml").text # HTML decoding
    text = text.lower() # lowercase text
    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text
    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text
    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text
    return text
    
df['post'] = df['post'].apply(clean_text)

from sklearn.feature_extraction.text import TfidfVectorizer


vectorizer = TfidfVectorizer(stop_words='english',
max_features= 20000,
max_df = 0.5, 
smooth_idf=True)
X = df['post']
y = df.tags
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 42)

tf=vectorizer.fit_transform(X_train)
test=vectorizer.transform(X_test)
print(tf.shape)

from sklearn.decomposition import TruncatedSVD
from sklearn.naive_bayes import GaussianNB

svd_model = TruncatedSVD(n_components=1000, algorithm='randomized', n_iter=100, random_state=42)

tf1=svd_model.fit_transform(tf)

test1=svd_model.transform(test)

cd drive/

from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.metrics import classification_report

from sklearn import metrics
clf = GaussianNB().fit(tf1, y_train)
predicted= clf.predict(test1)
print(predicted)
print("GaussianNB Accuracy:",metrics.accuracy_score(y_test, predicted))
print(classification_report(y_test, predicted))